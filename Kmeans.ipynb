{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn import feature_extraction\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.manifold import MDS\n",
    "%matplotlib inline\n",
    "\n",
    "hg = movie_df.sort(['gross'], ascending = False)\n",
    "hg = hg.reset_index(drop=True)\n",
    "hg = hg.head(1000)\n",
    "\n",
    "titles = list(hg['movie_title']) \n",
    "keywords = list(hg['plot_keywords'])\n",
    "keywords = [key.replace('|', ' ') for key in keywords]\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.9, max_features=200000,\n",
    "                                 min_df=0.01, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize, ngram_range=(1,3))\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(keywords) \n",
    "terms = tfidf_vectorizer.get_feature_names() \n",
    "\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)\n",
    "k = 5\n",
    "\n",
    "km = KMeans(n_clusters=k)\n",
    "km.fit(tfidf_matrix)\n",
    "clusters = km.labels_.tolist()\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "asc_order_centroids = km.cluster_centers_.argsort()#[:, ::-1]\n",
    "order_centroids = asc_order_centroids[:,::-1]\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "labels = [] \n",
    "for i in range(5):\n",
    "    print(\"Cluster {}:\".format(i))\n",
    "    temp = {i: []}\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        temp[i].append(terms[ind])\n",
    "        print(' {}'.format(terms[ind]))\n",
    "    print('')\n",
    "    labels.append(temp) \n",
    "    \n",
    "words = ['', '', '', '', ''] \n",
    "index = 0 \n",
    "for i in labels: \n",
    "    for j in i: \n",
    "        for k in range(len(i[j])): \n",
    "            if k == (len(i[j]) - 1): \n",
    "                words[index] += i[j][k]\n",
    "            else: \n",
    "                words[index] += i[j][k] + ','\n",
    "    index += 1 \n",
    "    \n",
    "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
    "pos = mds.fit_transform(dist) \n",
    "xs, ys = pos[:, 0], pos[:, 1]\n",
    "\n",
    "# set up colors per clusters using a dict\n",
    "cluster_colors = {0: '#16a085', 1: '#2c3e50', 2: '#8e44ad', 3: '#2980b9', 4: '#e67e22'} \n",
    "\n",
    "# set up cluster names using a dict\n",
    "cluster_names = {0: words[0], \n",
    "                 1: words[1], \n",
    "                 2: words[2], \n",
    "                 3: words[3], \n",
    "                 4: words[4]}\n",
    "\n",
    "df = pd.DataFrame(dict(x=xs, y=ys, label=clusters, title=titles)) \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cluster groups \n",
    "groups = df.groupby('label')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8)) \n",
    "ax.margins(0.10) \n",
    "\n",
    "#iterate through groups to layer the plot\n",
    "for name, group in groups:\n",
    "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=cluster_names[name], color=cluster_colors[name], mec='none')\n",
    "    ax.set_aspect('auto')\n",
    "    ax.tick_params(\\\n",
    "        axis= 'x',          \n",
    "        which='both',      \n",
    "        bottom='off',      \n",
    "        top='off',         \n",
    "        labelbottom='off')\n",
    "    ax.tick_params(\\\n",
    "        axis= 'y',         \n",
    "        which='both',      \n",
    "        left='off',      \n",
    "        top='off',         \n",
    "        labelleft='off')\n",
    "    \n",
    "ax.legend()\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_clusters(X,max_clusters):\n",
    "    error = np.zeros(max_clusters+1)\n",
    "    error[0] = 0;\n",
    "    for k in range(1,max_clusters+1):\n",
    "        kmeans = KMeans(init='k-means++', n_clusters=k, n_init=10)\n",
    "        kmeans.fit_predict(X)\n",
    "        error[k] = kmeans.inertia_\n",
    "\n",
    "    plt.plot(range(1,len(error)),error[1:])\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Error')\n",
    "    \n",
    "evaluate_clusters(tfidf_matrix, 6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
