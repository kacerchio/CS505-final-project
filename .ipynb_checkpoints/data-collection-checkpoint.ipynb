{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This script is responsible for intial results of \n",
    "cleaning CSV movie_metadata retrieved from kaggle.com\n",
    "'''\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "movie_df = pd.read_csv('movie_metadata.csv')\n",
    "\n",
    "# Deleting columns that are not useful \n",
    "delete = ['color', 'num_critic_for_reviews', 'actor_3_facebook_likes', 'actor_1_facebook_likes','movie_imdb_link', 'country', 'language', \n",
    "         'aspect_ratio', 'num_user_for_reviews', 'num_voted_users', 'actor_2_facebook_likes', 'content_rating', 'director_facebook_likes',\n",
    "         'cast_total_facebook_likes', 'movie_facebook_likes']\n",
    "for d in delete: del movie_df[d]\n",
    "\n",
    "# Delete rows with empty cells for any column     \n",
    "for c in movie_df: \n",
    "    movie_df[c].replace('', np.nan, inplace=True)\n",
    "    movie_df.dropna(subset=[c], inplace=True)\n",
    "\n",
    "movie_df = movie_df.reset_index(drop=True)\n",
    "\n",
    "genres_set = set() \n",
    "for i in range(len(movie_df)): \n",
    "    g = movie_df['genres'][i].split('|')\n",
    "    genres_set.update(g)\n",
    "\n",
    "genres = list(genres_set)\n",
    "genres = dict.fromkeys(genres)\n",
    "genres_ct = {key: 0 for key in genres} \n",
    "\n",
    "# Count number of movies that belong to each genre\n",
    "for i in range(len(movie_df)): \n",
    "    g = movie_df['genres'][i].split('|')\n",
    "    for item in g: \n",
    "        if item in genres: \n",
    "            genres_ct[item] += 1 \n",
    "\n",
    "# Get the top 5 genres \n",
    "sortedCounts = [(genres_ct[key], key) for key in genres_ct]\n",
    "sortedCounts.sort()\n",
    "sortedCounts.reverse() \n",
    "top_genres = [item[1] for item in sortedCounts[:5]] \n",
    "\n",
    "# Build list of row indices that need to dropped because they are not in the top 5 genres\n",
    "topg_set = set(top_genres) \n",
    "drop = [] \n",
    "for i in range(len(movie_df)):\n",
    "    g = set(movie_df['genres'][i].split('|'))\n",
    "    if len(set.intersection(g, topg_set)) == 0:\n",
    "        drop.append(i)\n",
    "\n",
    "movie_df = movie_df.drop(movie_df.index[drop])\n",
    "movie_df = movie_df.reset_index(drop=True) \n",
    "movie_df.to_csv('movie_clean_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female protagonist|outer space|father son relationship|patricide|droid\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This script is responsible for scraping additional movie \n",
    "data from boxofficemojo.com and imdb.com\n",
    "'''\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import csv\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "columns = ['director_name', 'duration', 'actor_2_name', 'gross', 'genres', 'actor_1_name', 'movie_title', 'actor_3_name', 'facenumber_in_poster', 'plot_keywords', 'budget', 'title_year', 'imdb_score']\n",
    "csv_file = open('movie_scrape.csv', 'w')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow(columns)\n",
    "\n",
    "def removeNonNumeric(str):\n",
    "    return re.sub(\"[^0-9]\", \"\", str)\n",
    "    \n",
    "def scrapeData(soup):\n",
    "    \n",
    "    for title in soup.find_all('h3', class_='lister-item-header'):\n",
    "        \n",
    "        movie_title = title.find('a').text\n",
    "        movie_url = title.find('a')['href']\n",
    "        m = urllib.request.urlopen('https://www.imdb.com/' + movie_url).read()\n",
    "        msoup = BeautifulSoup(m, 'html.parser')\n",
    "        \n",
    "        imdb_score = msoup.find_all('span', attrs={'itemprop':'ratingValue'})[0].text\n",
    "        \n",
    "        duration = removeNonNumeric(msoup.find_all('time')[1].text)\n",
    "        \n",
    "        genre_div = msoup.find_all('div', itemprop='genre')[0].find_all('a')\n",
    "        i, genres = 0, ''\n",
    "        for g in genre_div:\n",
    "            i += 1\n",
    "            if i == len(genre_div):\n",
    "                genres += g.text\n",
    "            else:\n",
    "                genres += g.text + ' |'\n",
    "\n",
    "        director_name = msoup.find_all(attrs={'itemprop':'director'})[0].find('span').text\n",
    "        stars_spans = msoup.find_all(attrs={'itemprop':'actors'})\n",
    "        i, actor_1_name, actor_2_name, actor_3_name = 1, '', '', ''\n",
    "        for s in stars_spans:\n",
    "            if i == 1:\n",
    "                actor_1_name += s.find('span').text\n",
    "            elif i == 2:\n",
    "                actor_2_name += s.find('span').text\n",
    "            else:\n",
    "                actor_3_name += s.find('span').text\n",
    "            i += 1\n",
    "        \n",
    "        details_divs = msoup.find_all('div', id='titleDetails')[0].find_all('div')\n",
    "        budget, gross, title_year = '', '', ''\n",
    "        for d in details_divs:\n",
    "            try:\n",
    "                if d.find('h4').text == 'Budget:':\n",
    "                    budget = removeNonNumeric(d.text.replace('\\n',''))\n",
    "                elif d.find('h4').text == 'Gross:':\n",
    "                    gross = removeNonNumeric(d.text.replace('\\n',''))\n",
    "                elif d.find('h4').text == 'Release Date:':\n",
    "                    date = d.text.split('\\n')[1].split('\\s')[0]\n",
    "                    title_year = re.search('\\d{4}', date).group(0)\n",
    "            except AttributeError:\n",
    "                pass\n",
    "        \n",
    "        keywords_span = msoup.find_all('span', attrs={'itemprop':'keywords'})\n",
    "        keywords = [key.text for key in keywords_span]\n",
    "        plot_keywords = ''\n",
    "        i = 0 \n",
    "        for word in keywords: \n",
    "            i += 1 \n",
    "            if i == len(keywords):\n",
    "                plot_keywords += word \n",
    "            else: \n",
    "                plot_keywords += word + '|'\n",
    "        \n",
    "        facenumber_in_poster = 0\n",
    "        new_entry = [director_name, duration, actor_2_name, gross, genres, actor_1_name, movie_title, actor_3_name, facenumber_in_poster, plot_keywords, budget, title_year, imdb_score]\n",
    "        csv_writer.writerow(new_entry)\n",
    "        print(new_entry)\n",
    "        break\n",
    "\n",
    "r = urllib.request.urlopen('http://www.imdb.com/search/title?year=2015,2015&title_type=feature&sort=boxoffice_gross_us,desc').read()\n",
    "soup = BeautifulSoup(r, 'html.parser')\n",
    "\n",
    "scrapeData(soup)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
