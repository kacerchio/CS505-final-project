{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This script is responsible for intial results of \n",
    "cleaning CSV movie_metadata retrieved from kaggle.com\n",
    "'''\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "movie_df = pd.read_csv('movie_metadata.csv')\n",
    "\n",
    "# Deleting columns that are not useful \n",
    "delete = ['color', 'num_critic_for_reviews', 'actor_3_facebook_likes', 'actor_1_facebook_likes','movie_imdb_link', 'country', 'language', \n",
    "         'aspect_ratio', 'num_user_for_reviews', 'num_voted_users', 'actor_2_facebook_likes', 'content_rating', 'director_facebook_likes',\n",
    "         'cast_total_facebook_likes', 'movie_facebook_likes']\n",
    "for d in delete: del movie_df[d]\n",
    "\n",
    "# Delete rows with empty cells for any column     \n",
    "for c in movie_df: \n",
    "    movie_df[c].replace('', np.nan, inplace=True)\n",
    "    movie_df.dropna(subset=[c], inplace=True)\n",
    "\n",
    "movie_df = movie_df.reset_index(drop=True)\n",
    "\n",
    "genres_set = set() \n",
    "for i in range(len(movie_df)): \n",
    "    g = movie_df['genres'][i].split('|')\n",
    "    genres_set.update(g)\n",
    "\n",
    "genres = list(genres_set)\n",
    "genres = dict.fromkeys(genres)\n",
    "genres_ct = {key: 0 for key in genres} \n",
    "\n",
    "# Count number of movies that belong to each genre\n",
    "for i in range(len(movie_df)): \n",
    "    g = movie_df['genres'][i].split('|')\n",
    "    for item in g: \n",
    "        if item in genres: \n",
    "            genres_ct[item] += 1 \n",
    "\n",
    "# Get the top 5 genres \n",
    "sortedCounts = [(genres_ct[key], key) for key in genres_ct]\n",
    "sortedCounts.sort()\n",
    "sortedCounts.reverse() \n",
    "top_genres = [item[1] for item in sortedCounts[:5]] \n",
    "\n",
    "# Build list of row indices that need to dropped because they are not in the top 5 genres\n",
    "topg_set = set(top_genres) \n",
    "drop = [] \n",
    "for i in range(len(movie_df)):\n",
    "    g = set(movie_df['genres'][i].split('|'))\n",
    "    if len(set.intersection(g, topg_set)) == 0:\n",
    "        drop.append(i)\n",
    "\n",
    "movie_df = movie_df.drop(movie_df.index[drop])\n",
    "movie_df = movie_df.reset_index(drop=True) \n",
    "movie_df.to_csv('movie_clean_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n",
      "Retrieving next page of movies\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/Users/abbytan/anaconda/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.6 and older\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-47845ebb25f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_base\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnext_page\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrapeData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0mstop_ct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Retrieving next page of movies'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-47845ebb25f0>\u001b[0m in \u001b[0;36mscrapeData\u001b[0;34m(soup)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mKEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'44053727cda344da8fbf58088dce0044'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mCF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposter_img_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mfacenumber_in_poster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abbytan/anaconda/lib/python3.5/site-packages/cognitive_face/face.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(image, face_id, landmarks, attributes)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     return util.request('POST', url, headers=headers, params=params, json=json,\n\u001b[0;32m---> 40\u001b[0;31m                         data=data)\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abbytan/anaconda/lib/python3.5/site-packages/cognitive_face/util.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, data, json, headers, params)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     response = requests.request(method, url, params=params, data=data,\n\u001b[0;32m---> 72\u001b[0;31m                                 json=json, headers=headers)\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Handle result and raise custom exception when something wrong.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abbytan/anaconda/lib/python3.5/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abbytan/anaconda/lib/python3.5/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    473\u001b[0m         }\n\u001b[1;32m    474\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abbytan/anaconda/lib/python3.5/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abbytan/anaconda/lib/python3.5/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    401\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m                 )\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abbytan/anaconda/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, **response_kw)\u001b[0m\n\u001b[1;32m    576\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abbytan/anaconda/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    385\u001b[0m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.6 and older\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abbytan/anaconda/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1198\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abbytan/anaconda/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abbytan/anaconda/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abbytan/anaconda/lib/python3.5/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abbytan/anaconda/lib/python3.5/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m    927\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m                   self.__class__)\n\u001b[0;32m--> 929\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abbytan/anaconda/lib/python3.5/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abbytan/anaconda/lib/python3.5/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \"\"\"\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "This script is responsible for scraping \n",
    "additional movie data from imdb.com\n",
    "'''\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import csv\n",
    "import re\n",
    "import datetime\n",
    "import cognitive_face as CF\n",
    "import time\n",
    "\n",
    "# Create or overwrite 'movie_scrape.csv' file\n",
    "columns = ['director_name', 'duration', 'actor_2_name', 'gross', 'genres', 'actor_1_name', 'movie_title', 'actor_3_name', 'facenumber_in_poster', 'plot_keywords', 'budget', 'title_year', 'imdb_score']\n",
    "csv_file = open('movie_scrape_2012.csv', 'w')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow(columns)\n",
    "\n",
    "# Helper function to remove all non-numeric characters from a string\n",
    "def removeNonNumeric(str):\n",
    "    return re.sub(\"[^0-9]\", \"\", str)\n",
    "\n",
    "# Function to scrape data from IMDB box office results\n",
    "def scrapeData(soup):\n",
    "    \n",
    "    # Finds the link for next page\n",
    "    pagination = soup.find('div', {'class':'desc'})\n",
    "    link_tag = pagination.find('a', {'class':'lister-page-next next-page'})\n",
    "    \n",
    "    for title in soup.find_all('h3', class_='lister-item-header'):\n",
    "        \n",
    "        movie_title = title.find('a').text\n",
    "        movie_url = title.find('a')['href']\n",
    "        m = urllib.request.urlopen('https://www.imdb.com/' + movie_url).read()\n",
    "        msoup = BeautifulSoup(m, 'html.parser')\n",
    "        \n",
    "        try:\n",
    "            imdb_score = msoup.find_all('span', attrs={'itemprop':'ratingValue'})[0].text\n",
    "        except IndexError:\n",
    "            imdb_score = ''\n",
    "            \n",
    "        try:\n",
    "            genre_div = msoup.find_all('div', itemprop='genre')[0].find_all('a')\n",
    "            i, genres = 0, ''\n",
    "            for g in genre_div:\n",
    "                i += 1\n",
    "                if i == len(genre_div):\n",
    "                    genres += g.text\n",
    "                else:\n",
    "                    genres += g.text + ' |'\n",
    "        except IndexError:\n",
    "            genres = ''\n",
    "\n",
    "        try:\n",
    "            director_name = msoup.find_all(attrs={'itemprop':'director'})[0].find('span').text\n",
    "        except IndexError:\n",
    "            director_name = ''\n",
    "        \n",
    "        try:\n",
    "            stars_spans = msoup.find_all(attrs={'itemprop':'actors'})\n",
    "            i, actor_1_name, actor_2_name, actor_3_name = 1, '', '', ''\n",
    "            for s in stars_spans:\n",
    "                if i == 1:\n",
    "                    actor_1_name += s.find('span').text\n",
    "                elif i == 2:\n",
    "                    actor_2_name += s.find('span').text\n",
    "                else:\n",
    "                    actor_3_name += s.find('span').text\n",
    "                i += 1\n",
    "        except TypeError:\n",
    "            actor_1_name, actor_2_name, actor_3_name = '', '', ''\n",
    "        \n",
    "        try:\n",
    "            details_divs = msoup.find_all('div', id='titleDetails')[0].find_all('div')\n",
    "            budget, gross, title_year, duration = '', '', '', ''\n",
    "            for d in details_divs:\n",
    "                try:\n",
    "                    if d.find('h4').text == 'Budget:':\n",
    "                        budget = removeNonNumeric(d.text.replace('\\n',''))\n",
    "                    elif d.find('h4').text == 'Gross:':\n",
    "                        gross = removeNonNumeric(d.text.replace('\\n',''))\n",
    "                    elif d.find('h4').text == 'Release Date:':\n",
    "                        date = d.text.split('\\n')[1].split('\\s')[0]\n",
    "                        title_year = re.search('\\d{4}', date).group(0)\n",
    "                    elif d.find('h4').text == 'Runtime:':\n",
    "                        duration = removeNonNumeric(d.text.replace('\\n',''))\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "        except IndexError:\n",
    "            budget, gross, title_year, duration = '', '', '', ''\n",
    "\n",
    "        try: \n",
    "            keywords_span = msoup.find_all('span', attrs={'itemprop':'keywords'})\n",
    "            keywords = [key.text for key in keywords_span]\n",
    "            i, plot_keywords = 0, ''\n",
    "            for word in keywords: \n",
    "                i += 1 \n",
    "                if i == len(keywords):\n",
    "                    plot_keywords += word \n",
    "                else: \n",
    "                    plot_keywords += word + '|'\n",
    "        except TypeError:\n",
    "            plot_keywords = ''\n",
    "        \n",
    "        try:\n",
    "            poster_img_url = msoup.find_all('img', attrs={'itemprop':'image'})[0]['src']\n",
    "            KEY = '44053727cda344da8fbf58088dce0044'\n",
    "            CF.Key.set(KEY)\n",
    "            result = CF.face.detect(poster_img_url)\n",
    "            facenumber_in_poster = len(result)\n",
    "        except IndexError:\n",
    "            facenumber_in_poster = 0\n",
    "        \n",
    "        new_entry = [director_name, duration, actor_2_name, gross, genres, actor_1_name, movie_title, actor_3_name, facenumber_in_poster, plot_keywords, budget, title_year, imdb_score]\n",
    "        csv_writer.writerow(new_entry)\n",
    "        \n",
    "        time.sleep(2)\n",
    "        \n",
    "    return link_tag\n",
    "\n",
    "# url_base = 'http://www.imdb.com/search/title' \n",
    "# next_page = '?year=2015,2015&title_type=feature&sort=boxoffice_gross_us,desc'\n",
    "# stop_ct = 0\n",
    "# while True: \n",
    "#     r = urllib.request.urlopen(url_base + next_page).read()\n",
    "#     soup = BeautifulSoup(r, 'html.parser')\n",
    "#     tag = scrapeData(soup)\n",
    "#     stop_ct += 1\n",
    "#     print('Retrieving next page of movies')\n",
    "#     if tag is None and stop_ct <= 20: \n",
    "#         print('Done')\n",
    "#         break\n",
    "#     else:\n",
    "#         next_page = tag['href']\n",
    "\n",
    "# url_base = 'http://www.imdb.com/search/title' \n",
    "# next_page = '?year=2014,2014&title_type=feature&sort=boxoffice_gross_us,desc'\n",
    "# stop_ct = 0\n",
    "# while True: \n",
    "#     r = urllib.request.urlopen(url_base + next_page).read()\n",
    "#     soup = BeautifulSoup(r, 'html.parser')\n",
    "#     tag = scrapeData(soup)\n",
    "#     stop_ct += 1\n",
    "#     print('Retrieving next page of movies')\n",
    "#     if tag is None and stop_ct <= 20: \n",
    "#         print('Done')\n",
    "#         break\n",
    "#     else:\n",
    "#         next_page = tag['href']\n",
    "\n",
    "# url_base = 'http://www.imdb.com/search/title' \n",
    "# next_page = '?year=2013,2013&title_type=feature&sort=boxoffice_gross_us,desc'\n",
    "# stop_ct = 0\n",
    "# while True: \n",
    "#     r = urllib.request.urlopen(url_base + next_page).read()\n",
    "#     soup = BeautifulSoup(r, 'html.parser')\n",
    "#     tag = scrapeData(soup)\n",
    "#     stop_ct += 1\n",
    "#     print('Retrieving next page of movies')\n",
    "#     if tag is None and stop_ct <= 20: \n",
    "#         print('Done')\n",
    "#         break\n",
    "#     else:\n",
    "#         next_page = tag['href']\n",
    "\n",
    "url_base = 'http://www.imdb.com/search/title' \n",
    "next_page = '?year=2012,2012&title_type=feature&sort=boxoffice_gross_us,desc'\n",
    "stop_ct = 0\n",
    "while True: \n",
    "    r = urllib.request.urlopen(url_base + next_page).read()\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    tag = scrapeData(soup)\n",
    "    stop_ct += 1\n",
    "    print('Retrieving next page of movies')\n",
    "    if tag is None and stop_ct <= 20: \n",
    "        print('Done')\n",
    "        break\n",
    "    else:\n",
    "        next_page = tag['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4487\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This script is responsible for cleaning and merging the \n",
    "scraped movie data with the existing movie data set\n",
    "'''\n",
    "# Helper function to delete rows with empty cells for any column in movie dataframe    \n",
    "def deleteEmptyCol(movie_df):\n",
    "    for c in movie_df: \n",
    "        movie_df[c].replace('', np.nan, inplace=True)\n",
    "        movie_df.dropna(subset=[c], inplace=True)\n",
    "\n",
    "    movie_df = movie_df.reset_index(drop=True)\n",
    "\n",
    "# Helper function to remove movies that are not in the top 5 genres\n",
    "def topGenres(movie_df):\n",
    "    genres_set = set() \n",
    "    for i in movie_df['genres'].iteritems():\n",
    "        g = i[1].split('|')\n",
    "        genres_set.update(g)\n",
    "\n",
    "    genres = list(genres_set)\n",
    "    genres = dict.fromkeys(genres)\n",
    "    genres_ct = {key: 0 for key in genres} \n",
    "\n",
    "    # Count number of movies that belong to each genre\n",
    "    for i in movie_df['genres'].iteritems():\n",
    "        g = i[1].split('|')\n",
    "        for item in g: \n",
    "            if item in genres: \n",
    "                genres_ct[item] += 1 \n",
    "\n",
    "    # Get the top 5 genres \n",
    "    sortedCounts = [(genres_ct[key], key) for key in genres_ct]\n",
    "    sortedCounts.sort()\n",
    "    sortedCounts.reverse() \n",
    "    top_genres = [item[1] for item in sortedCounts[:5]] \n",
    "\n",
    "    # Build list of row indices that need to dropped because they are not in the top 5 genres\n",
    "    topg_set = set(top_genres) \n",
    "    drop = [] \n",
    "    for i in movie_df['genres'].iteritems():\n",
    "        g = set(i[1].split('|'))\n",
    "        if len(set.intersection(g, topg_set)) == 0:\n",
    "            drop.append(i)\n",
    "    \n",
    "movie_df_2015 = pd.read_csv('movie_scrape_2015.csv')\n",
    "deleteEmptyCol(movie_df_2015)\n",
    "movie_df_2014 = pd.read_csv('movie_scrape_2014.csv')\n",
    "deleteEmptyCol(movie_df_2014)\n",
    "movie_df_2013 = pd.read_csv('movie_scrape_2013.csv')\n",
    "deleteEmptyCol(movie_df_2013)\n",
    "movie_df_2012 = pd.read_csv('movie_scrape_2012.csv')\n",
    "deleteEmptyCol(movie_df_2012)\n",
    "\n",
    "kaggle_movie_df = pd.read_csv('movie_clean_metadata.csv')\n",
    "\n",
    "frames = [movie_df_2015, movie_df_2014, movie_df_2013, movie_df_2012, kaggle_movie_df]\n",
    "scraped_merge = pd.concat(frames)\n",
    "print(len(scraped_merge))\n",
    "del scraped_merge['Unnamed: 0']\n",
    "\n",
    "topGenres(scraped_merge)\n",
    "scraped_merge = scraped_merge.reset_index(drop=True)\n",
    "\n",
    "scraped_merge.to_csv('movie_master_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
